# ğŸ¯ AURORA - Quick Reference Guide

## ğŸš€ Quick Start Commands

### Start AURORA
```bash
./start.sh
```

### Access Points
- **Dashboard**: http://localhost:8501
- **API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

### Stop Services
```bash
# Press Ctrl+C in the terminal running start.sh
```

## ğŸ“‹ Common Tasks

### 1. Generate Test Data

```bash
# Activate virtual environment first
source venv/bin/activate

# Run data generator
python scripts/generate_data.py
```

Options:
1. Generate batch data (20 samples)
2. Simulate model degradation (60s)
3. Continuous monitoring (10s interval)
4. Single analysis test

### 2. Initialize/Reset Database

```bash
# Delete existing database
rm aurora.db

# Re-initialize
python scripts/init_db.py
```

### 3. Test API Endpoints

```bash
# Health check
curl http://localhost:8000/health

# Trigger analysis
curl -X POST http://localhost:8000/api/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "model_metrics": {"accuracy": 0.72, "latency_ms": 650},
    "data_drift": {"detected": true, "score": 0.65},
    "system_load": {"cpu_usage": 0.7}
  }'

# Get recent metrics
curl http://localhost:8000/api/metrics/latest?limit=10

# Get decisions
curl http://localhost:8000/api/decisions?limit=10
```

### 4. View Logs

```bash
# Backend logs
tail -f backend.log

# Frontend logs
tail -f frontend.log

# Both
tail -f backend.log frontend.log
```

## ğŸ³ Docker Commands

### Start with Docker

```bash
# Build and start
docker-compose up -d

# View logs
docker-compose logs -f aurora

# Stop
docker-compose down

# Rebuild
docker-compose up -d --build
```

### Access Docker Services

- Dashboard: http://localhost:8501
- API: http://localhost:8000
- PostgreSQL: localhost:5432

## ğŸ§ª Testing Scenarios

### Scenario 1: Model Degradation

```python
# In Python or use the dashboard
import requests

response = requests.post("http://localhost:8000/api/analyze", json={
    "model_metrics": {
        "accuracy": 0.68,  # Low accuracy
        "latency_ms": 450
    },
    "data_drift": {
        "detected": True,
        "score": 0.75  # High drift
    },
    "system_load": {
        "cpu_usage": 0.5,
        "memory_usage": 0.4,
        "gpu_usage": 0.3
    }
})

print(response.json())
# Expected: Planner recommends RETRAIN, Critic approves, Executor submits job
```

### Scenario 2: High Latency

```python
response = requests.post("http://localhost:8000/api/analyze", json={
    "model_metrics": {
        "accuracy": 0.85,  # Good accuracy
        "latency_ms": 1200  # High latency
    },
    "data_drift": {
        "detected": False,
        "score": 0.1
    },
    "system_load": {
        "cpu_usage": 0.6,
        "memory_usage": 0.5,
        "gpu_usage": 0.4
    }
})

print(response.json())
# Expected: Planner recommends CACHE, Critic approves, Executor enables caching
```

### Scenario 3: Healthy System

```python
response = requests.post("http://localhost:8000/api/analyze", json={
    "model_metrics": {
        "accuracy": 0.92,  # Excellent
        "latency_ms": 350  # Fast
    },
    "data_drift": {
        "detected": False,
        "score": 0.05
    },
    "system_load": {
        "cpu_usage": 0.4,
        "memory_usage": 0.3,
        "gpu_usage": 0.2
    }
})

print(response.json())
# Expected: NO_ACTION - system healthy
```

## ğŸ”§ Configuration

### Environment Variables (.env)

```bash
# Minimal setup (SQLite)
DATABASE_URL=sqlite:///./aurora.db
GCP_PROJECT_ID=your-project-id
PINECONE_API_KEY=not-required-for-faiss

# Production setup (PostgreSQL)
DATABASE_URL=postgresql://user:password@localhost:5432/aurora
GCP_PROJECT_ID=aurora-ml-system
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
PINECONE_API_KEY=your-pinecone-key
```

### Agent Thresholds

Edit `backend/config.py`:

```python
critic_threshold: float = 0.85  # Minimum confidence for approval
max_retries: int = 3  # Max retry attempts
```

## ğŸ“Š Dashboard Features

### Overview Tab
- System health metrics
- Active models count
- Average accuracy and latency
- Recent decisions summary
- Performance trends
- Latency distribution

### Agents Tab
- Manual analysis trigger
- Adjust model parameters
- View agent decisions
- See reasoning and confidence
- Execution results

### Metrics Tab
- Detailed metrics table
- Model selector
- Drift analysis charts
- Historical performance

### Memory Tab
- Search system memory
- View similar past cases
- Memory statistics
- RAG retrieval testing

## ğŸ” Troubleshooting

### Port Already in Use

```bash
# Kill process on port 8000
lsof -ti:8000 | xargs kill -9

# Kill process on port 8501
lsof -ti:8501 | xargs kill -9
```

### Database Locked

```bash
# Stop all services
# Delete database
rm aurora.db
# Restart
./start.sh
```

### Import Errors

```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

### Dashboard Not Loading

```bash
# Check if backend is running
curl http://localhost:8000/health

# Restart frontend only
streamlit run frontend/dashboard.py
```

## ğŸ“¦ Project Structure

```
AURORA/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agents/           # Planner, Critic, Executor
â”‚   â”œâ”€â”€ database/         # Models, connections
â”‚   â”œâ”€â”€ rag/             # Memory store
â”‚   â”œâ”€â”€ config.py        # Settings
â”‚   â””â”€â”€ main.py          # FastAPI app
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ dashboard.py     # Streamlit UI
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_db.py       # Database setup
â”‚   â””â”€â”€ generate_data.py # Test data
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ GCP_SETUP.md
â”‚   â”œâ”€â”€ N8N_SETUP.md
â”‚   â””â”€â”€ PROJECT_DOCUMENTATION.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ start.sh            # Quick start script
â””â”€â”€ .env               # Configuration
```

## ğŸ“ Next Steps

### For Development
1. âœ… Run `./start.sh`
2. âœ… Generate test data
3. âœ… Explore dashboard
4. âœ… Test API endpoints
5. â¬œ Integrate real models
6. â¬œ Configure GCP
7. â¬œ Set up n8n workflows

### For Research
1. â¬œ Design experiments
2. â¬œ Collect baseline metrics
3. â¬œ Run AURORA experiments
4. â¬œ Analyze results
5. â¬œ Write paper

### For Production
1. â¬œ Configure PostgreSQL
2. â¬œ Set up GCP Vertex AI
3. â¬œ Deploy to Cloud Run
4. â¬œ Configure monitoring
5. â¬œ Set up alerts

## ğŸ“š Documentation

- [Setup Guide](../SETUP.md)
- [GCP Configuration](./GCP_SETUP.md)
- [n8n Workflows](./N8N_SETUP.md)
- [Full Documentation](./PROJECT_DOCUMENTATION.md)

## ğŸ†˜ Getting Help

1. Check logs: `tail -f backend.log frontend.log`
2. Review documentation in `docs/`
3. Test with curl commands
4. Check GCP/Pinecone credentials
5. Verify Python version (3.10+)

---

**Quick Tip**: Use the data generator to create realistic test scenarios and see AURORA in action!
